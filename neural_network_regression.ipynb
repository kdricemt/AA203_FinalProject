import pandas as pd
import numpy as np 
import matplotlib.pyplot as plt
import sklearn

import pydot
import pydotplus
import graphviz
from sklearn.metrics import mean_squared_error

import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Input
from tensorflow.keras.layers import Input, Dense, BatchNormalization


def NormalizeData(data):
    normalized_data = (data - np.min(data,axis=0)) / (np.max(data,axis=0) - np.min(data,axis=0))
    return normalized_data

def Undo_NormalizeData(data_output, data):
    not_normalized_data = data_output * (np.max(data,axis=0) - np.min(data,axis=0) + np.min(data,axis=0)
    return not_normalized_data

df = pd.read_csv('') #TODO
#df = df.loc[()] #if necessary, conditionally select relevant data
targets = [''] #TODO outputs
predictors = [''] #TODO inputs
X_data = df[predictors]
Y_data = df[targets]
X_train = NormalizeData(X_data)
Y_train = NormalizeData(Y_data)
X_train = X_train.values
Y_train = Y_train.values

# Define Neural Network
keras.backend.clear_session()
model = Sequential()
model.add(Dense(1000), input_dim = len(X_train[1,:]), activation = "relu"))
model.add(Dense(500), activation = "relu"))
model.add(Dense(250), activation = "relu"))
model.add(Dense(100), activation = "relu"))
model.add(Dense(len(Y_train[1,:])))
model.summary()

model.compile(loss = "mean_squared_error", optimizer = "adam")
history = model.fit(X_train, Y_train, epochs=100, batch_size=5,shuffle=True)
print('finished training, ready to predict. If necessary, ready to validate.')

reshaped_X = X_train[0,:].reshape(1,len(X_train[1,:])) #change the 0th index of X_train to see different datapoints
Y_output_normalized = model.predict(reshaped_X)
Y_output_final = Undo_NormalizeData(Y_output_normalized, Y_data)
print(Y_output_final)

